# 0308 腾讯-PCG-QQ 算法应用研究岗 二面
这一面只问了项目，掺杂着项目问了各种算法问题，一共三十分钟左右，没有问其他八股。
## 项目
和一面大体差不多，然后面试官更多的问了些实际问题。
    
#### Q: 聊到一个的目标检测的时候，问目标检测使用的框架，然后问了YOLOV5和之前的版本有什么区别。
**A:** 主要答了V1之后引入的anchor。
#### Q: 问了如果不光要目标检测，还要做非常细致的边缘识别的话要怎么做。
**A:** 这是语意分割的任务，暂时还没有做过这方面的项目，但是按照任务特性来说，现在主流的方式应该都是使用U-Net的结构，使用不同的特征提取方法来增强分割表现。然后顺带讲了做过的一个融合传统Canny算子和HED网络做边缘检测的项目，在特征层引入了Canny算子的边缘检测结果，从而提升了边缘检测的表现，应该可以为更加细致的语意分割提供一些参考。
#### Q: 在讲基于语音的毫米波的生成的时候，问了我们使用的生成框架。
**A:** 讲了使用的IGN的框架，以及为什么没用diffusion。因为慢，并且因为毫米波数据噪声大，我们的生成不需要非常高的质量。
#### Q: 在用Diffusion做生成的时候，你们采样过程是怎么样的。
**A:** 使用的是Cold Diffusion，简单讲了一下Cold Diffusion。所以采样过程是通过线性插值来的，和DDPM还有DDIM是有点不同的。

#### Q: 做过图片的去噪吗？
**A:** 使用过简单的U-Net结构和Diffusion做过去噪。

#### Q: 两者效果对比怎么样？
**A:** 使用U-Net的效果一般，出来的效果带着一层高斯模糊的感觉，PSNR在30dB以下。使用Diffusion的结果在30dB左右，同时因为使用的是DDPM，所以采样时间很长。但是耗时也更多。

#### Q: 有没有做过对于算法改进，而非网络结构的调整。
**A:** 暂时还没有有效的成果过。曾经尝试过在基于Diffusion的去噪中，使用SNR来替换原公式中的t从而使得模型更加适合语音去噪任务。但是最终实验的结果没有非常明显的提升。

#### Q: 了解过多模态大模型吗？
**A:** 对于大模型的原理了解得不是很多，但是对于多模态的方向，了解一些CLIP。大概讲了一下CLIP。

#### Q: 对知识蒸馏，模型剪枝有了解吗，在使用这些技巧的时候如何保证模型精度？
**A:** 使用过知识蒸馏和模型量化。但是对模型剪枝不太了解。怎么保证精度没答上来。

#### Q: 除了Python还对什么语言熟悉，主要用这个语言做些什么。
**A:** C++，很多模型的部署最后还是使用C++来进行部署的，但是还没有真正使用C++部署过模型。

#### Q: 有没有参与过什么开源项目？有没有自己的博客？
**A:** 没有。

